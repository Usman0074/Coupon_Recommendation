{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a469474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy.stats import uniform, randint, pointbiserialr, chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import category_encoders as ce\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, ShuffleSplit, GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, auc, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3704d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:/Dataset/couponrecommendation/coupon_recommendation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69be6ad8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination</th>\n",
       "      <th>passanger</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>coupon</th>\n",
       "      <th>expiration</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>maritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>CoffeeHouse</th>\n",
       "      <th>CarryAway</th>\n",
       "      <th>RestaurantLessThan20</th>\n",
       "      <th>Restaurant20To50</th>\n",
       "      <th>toCoupon_GEQ5min</th>\n",
       "      <th>toCoupon_GEQ15min</th>\n",
       "      <th>toCoupon_GEQ25min</th>\n",
       "      <th>direction_same</th>\n",
       "      <th>direction_opp</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>55</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Restaurant(&lt;20)</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>10AM</td>\n",
       "      <td>Carry out &amp; Take away</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>2h</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Urgent Place</td>\n",
       "      <td>Friend(s)</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>2PM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>1d</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Unmarried partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12679</th>\n",
       "      <td>Home</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>55</td>\n",
       "      <td>6PM</td>\n",
       "      <td>Carry out &amp; Take away</td>\n",
       "      <td>1d</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>1~3</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12680</th>\n",
       "      <td>Work</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>55</td>\n",
       "      <td>7AM</td>\n",
       "      <td>Carry out &amp; Take away</td>\n",
       "      <td>1d</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>1~3</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12681</th>\n",
       "      <td>Work</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>30</td>\n",
       "      <td>7AM</td>\n",
       "      <td>Coffee House</td>\n",
       "      <td>1d</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>1~3</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12682</th>\n",
       "      <td>Work</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>30</td>\n",
       "      <td>7AM</td>\n",
       "      <td>Bar</td>\n",
       "      <td>1d</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>1~3</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12683</th>\n",
       "      <td>Work</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>7AM</td>\n",
       "      <td>Restaurant(20-50)</td>\n",
       "      <td>2h</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>1~3</td>\n",
       "      <td>4~8</td>\n",
       "      <td>1~3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12684 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           destination  passanger weather  temperature  time  \\\n",
       "0      No Urgent Place      Alone   Sunny           55   2PM   \n",
       "1      No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "2      No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
       "3      No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "4      No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
       "...                ...        ...     ...          ...   ...   \n",
       "12679             Home    Partner   Rainy           55   6PM   \n",
       "12680             Work      Alone   Rainy           55   7AM   \n",
       "12681             Work      Alone   Snowy           30   7AM   \n",
       "12682             Work      Alone   Snowy           30   7AM   \n",
       "12683             Work      Alone   Sunny           80   7AM   \n",
       "\n",
       "                      coupon expiration  gender age      maritalStatus  ...  \\\n",
       "0            Restaurant(<20)         1d  Female  21  Unmarried partner  ...   \n",
       "1               Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "2      Carry out & Take away         2h  Female  21  Unmarried partner  ...   \n",
       "3               Coffee House         2h  Female  21  Unmarried partner  ...   \n",
       "4               Coffee House         1d  Female  21  Unmarried partner  ...   \n",
       "...                      ...        ...     ...  ..                ...  ...   \n",
       "12679  Carry out & Take away         1d    Male  26             Single  ...   \n",
       "12680  Carry out & Take away         1d    Male  26             Single  ...   \n",
       "12681           Coffee House         1d    Male  26             Single  ...   \n",
       "12682                    Bar         1d    Male  26             Single  ...   \n",
       "12683      Restaurant(20-50)         2h    Male  26             Single  ...   \n",
       "\n",
       "       CoffeeHouse CarryAway RestaurantLessThan20 Restaurant20To50  \\\n",
       "0            never       NaN                  4~8              1~3   \n",
       "1            never       NaN                  4~8              1~3   \n",
       "2            never       NaN                  4~8              1~3   \n",
       "3            never       NaN                  4~8              1~3   \n",
       "4            never       NaN                  4~8              1~3   \n",
       "...            ...       ...                  ...              ...   \n",
       "12679        never       1~3                  4~8              1~3   \n",
       "12680        never       1~3                  4~8              1~3   \n",
       "12681        never       1~3                  4~8              1~3   \n",
       "12682        never       1~3                  4~8              1~3   \n",
       "12683        never       1~3                  4~8              1~3   \n",
       "\n",
       "      toCoupon_GEQ5min toCoupon_GEQ15min toCoupon_GEQ25min direction_same  \\\n",
       "0                    1                 0                 0              0   \n",
       "1                    1                 0                 0              0   \n",
       "2                    1                 1                 0              0   \n",
       "3                    1                 1                 0              0   \n",
       "4                    1                 1                 0              0   \n",
       "...                ...               ...               ...            ...   \n",
       "12679                1                 0                 0              1   \n",
       "12680                1                 0                 0              0   \n",
       "12681                1                 0                 0              1   \n",
       "12682                1                 1                 1              0   \n",
       "12683                1                 0                 0              1   \n",
       "\n",
       "      direction_opp  Y  \n",
       "0                 1  1  \n",
       "1                 1  0  \n",
       "2                 1  1  \n",
       "3                 1  0  \n",
       "4                 1  0  \n",
       "...             ... ..  \n",
       "12679             0  1  \n",
       "12680             1  1  \n",
       "12681             0  0  \n",
       "12682             1  0  \n",
       "12683             0  0  \n",
       "\n",
       "[12684 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cd3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b85361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToType(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, new_type):\n",
    "        self.column = column\n",
    "        self.new_type = new_type\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X[self.column] = X[self.column].astype(self.new_type)\n",
    "        return X\n",
    "\n",
    "class RemoveDuplicates(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop_duplicates()\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns)\n",
    "\n",
    "class FillMissingWithRandom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for column in self.columns:\n",
    "            probabilities = X[column].value_counts(normalize=True).to_dict()\n",
    "            X[column].fillna(\n",
    "                np.random.choice(X[column].dropna().unique(), p=list(probabilities.values())),\n",
    "                inplace=True\n",
    "            )\n",
    "        return X\n",
    "\n",
    "class MapFrequencyVariables(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mappings):\n",
    "        self.mappings = mappings\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for variable, mapping in self.mappings.items():\n",
    "            X[f'{variable}_encoded'] = X[variable].map(mapping)\n",
    "        X.drop(columns=list(self.mappings.keys()), inplace=True)\n",
    "        return X\n",
    "\n",
    "class MapCategoricalVariables(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mappings):\n",
    "        self.mappings = mappings\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for variable, mapping in self.mappings.items():\n",
    "            X[f'{variable}_encoded'] = X[variable].map(mapping)\n",
    "            X[f'{variable}_encoded'].fillna(-1, inplace=True)\n",
    "            X.drop(columns=variable, inplace=True)\n",
    "        return X\n",
    "\n",
    "class MapDistance(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        conditions = [\n",
    "            (X['toCoupon_GEQ15min'] == 0),\n",
    "            (X['toCoupon_GEQ15min'] == 1) & (X['toCoupon_GEQ25min'] == 0),\n",
    "            (X['toCoupon_GEQ25min'] == 1)\n",
    "        ]\n",
    "        values = [0, 1, 2]\n",
    "        X['distance'] = np.select(conditions, values, default=None)\n",
    "        X['distance'] = pd.to_numeric(X['distance'], errors='coerce')\n",
    "        X.drop(['toCoupon_GEQ15min', 'toCoupon_GEQ25min'], axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "class MapWeather(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X['weather'] = X['weather'].apply(lambda x: 'Sunny' if x == 'Sunny' else 'Snow_Rain')\n",
    "        return X\n",
    "\n",
    "class SeparateVariables(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_predictors = X.drop(columns=['Y'])\n",
    "        y_target = X['Y']\n",
    "        return X_predictors, y_target\n",
    "    \n",
    "# Define the mappings\n",
    "frequency_mappings = {\n",
    "    'Bar': {'never': 1, 'less1': 2, '1~3': 3, '4~8': 4, 'gt8': 5},\n",
    "    'CoffeeHouse': {'never': 1, 'less1': 2, '1~3': 3, '4~8': 4, 'gt8': 5},\n",
    "    'CarryAway': {'never': 1, 'less1': 2, '1~3': 3, '4~8': 4, 'gt8': 5},\n",
    "    'RestaurantLessThan20': {'never': 1, 'less1': 2, '1~3': 3, '4~8': 4, 'gt8': 5},\n",
    "    'Restaurant20To50': {'never': 1, 'less1': 2, '1~3': 3, '4~8': 4, 'gt8': 5},\n",
    "}\n",
    "\n",
    "education_mapping = {\n",
    "    'Some High School': 1, 'High School Graduate': 2, 'Some college - no degree': 3,\n",
    "    'Associates degree': 5, 'Bachelors degree': 6, 'Graduate degree (Masters or Doctorate)': 7\n",
    "}\n",
    "\n",
    "income_mapping = {\n",
    "    'Less than $12500': 1, '$12500 - $24999': 2, '$25000 - $37499': 3, '$37500 - $49999': 4,\n",
    "    '$50000 - $62499': 5, '$62500 - $74999': 6, '$75000 - $87499': 7, '$87500 - $99999': 8,\n",
    "    '$100000 or More': 10\n",
    "}\n",
    "\n",
    "gender_mapping = {\n",
    "    'Male': 0, 'Female': 1\n",
    "}\n",
    "\n",
    "age_mapping = {\n",
    "    'below21': 1, '21': 2, '26': 3, '31': 4, '36': 5, '41': 6, '46': 6, '50plus': 7\n",
    "}\n",
    "data_pipeline = Pipeline([\n",
    "    ('remove_duplicates', RemoveDuplicates()),\n",
    "    ('drop_columns', DropColumns(columns=['car'])),\n",
    "    ('fill_missing_with_random', FillMissingWithRandom(columns=['Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50'])),\n",
    "    ('map_frequency_variables', MapFrequencyVariables(mappings=frequency_mappings)),\n",
    "    ('drop_unused_columns', DropColumns(columns=['toCoupon_GEQ5min', 'direction_opp', 'direction_same', 'temperature'])),\n",
    "    ('map_categorical_variables', MapCategoricalVariables(mappings={\n",
    "        'education': education_mapping,\n",
    "        'income': income_mapping,\n",
    "        'gender': gender_mapping,\n",
    "        'age': age_mapping\n",
    "    })),\n",
    "    ('map_distance', MapDistance()),\n",
    "    ('map_weather', MapWeather()),\n",
    "    ('convert_to_string', ConvertToType(column='has_children', new_type=str)),\n",
    "    ('separate_variables', SeparateVariables())\n",
    "    \n",
    "])\n",
    "\n",
    "# Apply the pipeline to your data\n",
    "processed_data_predictors, processed_data_target = data_pipeline.transform(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5621c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d983cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      " Mean training score: 0.6851\n",
      " Mean validation score: 0.6813\n",
      "\n",
      "RandomForestClassifier:\n",
      " Mean training score: 0.9964\n",
      " Mean validation score: 0.7508\n",
      "\n",
      "GradientBoostingClassifier:\n",
      " Mean training score: 0.7371\n",
      " Mean validation score: 0.7229\n",
      "\n",
      "SVC:\n",
      " Mean training score: 0.7999\n",
      " Mean validation score: 0.7434\n",
      "\n",
      "DecisionTreeClassifier:\n",
      " Mean training score: 0.9964\n",
      " Mean validation score: 0.6874\n",
      "\n",
      "KNeighborsClassifier:\n",
      " Mean training score: 0.7977\n",
      " Mean validation score: 0.6710\n",
      "\n",
      "GaussianNB:\n",
      " Mean training score: 0.6409\n",
      " Mean validation score: 0.6346\n",
      "\n",
      "XGBClassifier:\n",
      " Mean training score: 0.9063\n",
      " Mean validation score: 0.7578\n",
      "\n",
      "\n",
      "Best model name: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "X = processed_data_predictors\n",
    "Y = processed_data_target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify = Y)\n",
    "\n",
    "hot_encoding_vars = ['destination','passanger','weather','time','coupon','expiration','maritalStatus','occupation','has_children']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "    ('num', StandardScaler(), X.select_dtypes(include=['number']).columns), # Standardization added\n",
    "    ('cat', OneHotEncoder(), hot_encoding_vars)\n",
    "  ],\n",
    "  remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Create a pipeline for preprocessing and modeling\n",
    "pipeline = Pipeline([\n",
    "  ('preprocessor', preprocessor),\n",
    "  ('model', None) # placeholder for the model\n",
    "])\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation for each model, including hyperparameter tuning\n",
    "results = {}\n",
    "\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "best_mean_val_score = -1  # Initialize with a value lower than possible scores\n",
    "\n",
    "for model in models:\n",
    "    name = model.__class__.__name__\n",
    "    pipeline.set_params(model=model)\n",
    "    cv_results = cross_validate(pipeline, X_train, Y_train, cv=cv, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    mean_train_score = cv_results['train_score'].mean()\n",
    "    mean_val_score = cv_results['test_score'].mean()\n",
    "\n",
    "    results[name] = {\n",
    "        'mean_train_score': mean_train_score,\n",
    "        'mean_val_score': mean_val_score\n",
    "    }\n",
    "\n",
    "    if mean_val_score > best_mean_val_score:\n",
    "        best_mean_val_score = mean_val_score\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "# Print results for comparison\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}:\")  \n",
    "    print(f\" Mean training score: {result['mean_train_score']:.4f}\")\n",
    "    print(f\" Mean validation score: {result['mean_val_score']:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Print the best model and its name\n",
    "print(f\"\\nBest model name: {best_model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18336df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "379bccf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train,Y_train)\n\u001b[0;32m      3\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train,Y_train)\n",
    "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(preprocessor.transform(X_train))\n",
    "shap_summary_plot = shap.summary_plot(shap_values, preprocessor.transform(X_train), feature_names=feature_names, plot_type='bar')\n",
    "mean_abs_shap_values = np.abs(shap_values).mean(axis=0)\n",
    "top_20_feature_indices = np.argsort(mean_abs_shap_values)[-20:][::-1]\n",
    "top_20_features = [feature_names[i] for i in top_20_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0418b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_indices):\n",
    "        self.feature_indices = feature_indices\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline with preprocessor, feature extractor, and model\n",
    "shap_feature_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_extractor', FeatureExtractor(top_20_feature_indices)),\n",
    "    ('model', None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f474df",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_feature_pipeline.set_params(model = XGBClassifier())\n",
    "shap_feature_pipeline.fit(X_train,Y_train)\n",
    "\n",
    "train_accuracy = shap_feature_pipeline.score(X_train, Y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Obtain the validation accuracy\n",
    "val_accuracy = shap_feature_pipeline.score(X_val, Y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ceeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dist = {\n",
    " 'model__n_estimators': randint(100, 300),\n",
    " 'model__learning_rate': uniform(0.001, 0.3),\n",
    " 'model__max_depth': randint(2, 7),\n",
    " 'model__min_child_weight': randint(1, 10),\n",
    " 'model__subsample': uniform(0.8, 1.0 - 0.8),\n",
    " 'model__colsample_bytree': uniform(0.8, 1.0 - 0.8 ),\n",
    "}\n",
    "\n",
    "\n",
    "# Use RandomizedSearchCV to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(shap_feature_pipeline, param_distributions=param_dist, n_iter=330, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1, random_state=42, return_train_score=True)\n",
    "\n",
    "\n",
    "\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Get the best model from the random search\n",
    "best_xgb_model_random = random_search.best_estimator_\n",
    "\n",
    "# Fit the best model to the full training set\n",
    "best_xgb_model_random.fit(X_train, Y_train)\n",
    "\n",
    "# Calculate the train score\n",
    "train_score = best_xgb_model_random.score(X_train, Y_train)\n",
    "\n",
    "# Retrieve the mean train score from cross-validation\n",
    "mean_train_score_cv = np.mean(random_search.cv_results_['mean_train_score'])\n",
    "\n",
    "# Print the scores\n",
    "print(\"Train Score:\", train_score)\n",
    "print(\"Mean Train Score (CV):\", mean_train_score_cv)\n",
    "print(\"Best Mean Validation Score:\", random_search.best_score_)\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Compare the scores to assess overfitting\n",
    "# if train_score - random_search.best_score_ > 0.1:\n",
    "#     print(\"Warning: Potential overfitting detected. Train score is significantly higher than validation score.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a37b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff07042",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    colsample_bytree= 0.947571153381305,\n",
    "    learning_rate= 0.10503362197574638, \n",
    "    max_depth=7,\n",
    "    min_child_weight=1,\n",
    "    n_estimators=251,\n",
    "    subsample= 0.8465918949507268,\n",
    "    reg_alpha=0.2,  # L1 regularization\n",
    "    reg_lambda=10,   # L2 regularization\n",
    "    early_stopping_rounds=100,  # Set early stopping directly in the model\n",
    "    eval_metric='error'  # Set eval metric directly in the model\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "X = processed_data_predictors\n",
    "Y = processed_data_target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify = Y)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42, stratify=Y_train)\n",
    "\n",
    "\n",
    "eval_set = [(shap_feature_pipeline.set_params(model = None).transform(X_train),Y_train),\n",
    "           (shap_feature_pipeline.set_params(model=None).transform(X_val), Y_val)]\n",
    "shap_feature_pipeline.set_params(model = xgb_model)\n",
    "\n",
    "shap_feature_pipeline.fit(X_train, Y_train,\n",
    "    model__eval_set=eval_set\n",
    " )\n",
    "\n",
    "train_accuracy = shap_feature_pipeline.score(X_train, Y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Obtain the validation accuracy\n",
    "val_accuracy = shap_feature_pipeline.score(X_val, Y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27645523",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iteration = shap_feature_pipeline.named_steps['model'].best_iteration\n",
    "best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16007c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xgb_model.evals_result()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(results[\"validation_0\"][\"error\"], label=\"Training loss\")\n",
    "plt.plot(results[\"validation_1\"][\"error\"], label=\"Validation loss\")\n",
    "plt.axvline(best_iteration, color=\"gray\", label=\"Optimal tree number\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2335c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac679fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2e358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb_model = XGBClassifier(\n",
    "    colsample_bytree= 0.947571153381305,\n",
    "    learning_rate= 0.10503362197574638, \n",
    "    max_depth=7,\n",
    "    min_child_weight=1,\n",
    "    n_estimators=best_iteration,\n",
    "    subsample= 0.8465918949507268,\n",
    "    reg_alpha=0.2,  # L1 regularization\n",
    "    reg_lambda=10   # L2 regularization\n",
    "    \n",
    ")\n",
    "\n",
    "final_pipeline = shap_feature_pipeline.set_params(model = final_xgb_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bceac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline.fit(X_train,Y_train)\n",
    "final_pipeline.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = final_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8026951",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42daf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c636231",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(Y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the test set\n",
    "Y_pred_prob = final_pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f665d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(Y_test, Y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d77d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31e001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17304d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3594bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee9961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36123a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7421ab72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f6f6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa73ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adc50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4c86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da371cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925bcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
